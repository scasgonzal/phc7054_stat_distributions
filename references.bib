@article{knuth84,
  author = {Knuth, Donald E.},
  title = {Literate Programming},
  year = {1984},
  issue_date = {May 1984},
  publisher = {Oxford University Press, Inc.},
  address = {USA},
  volume = {27},
  number = {2},
  issn = {0010-4620},
  url = {https://doi.org/10.1093/comjnl/27.2.97},
  doi = {10.1093/comjnl/27.2.97},
  journal = {Comput. J.},
  month = may,
  pages = {97–111},
  numpages = {15}
}
@misc{cdc2022,
  title        = {COVID-19 Vaccination Coverage, United States, 2022},
  author       = {{Centers for Disease Control and Prevention}},
  year         = {2022},
  url          = {https://www.cdc.gov/vaccines/imz-managers/coverage/index.html},
  note         = {Accessed: 2025-09-15}
}

@article{hamzaBinomialDistributionMetaanalysis2008,
  title = {The Binomial Distribution of Meta-Analysis Was Preferred to Model within-Study Variability},
  author = {Hamza, Taye H. and {van Houwelingen}, Hans C. and Stijnen, Theo},
  year = {2008},
  month = jan,
  journal = {Journal of Clinical Epidemiology},
  volume = {61},
  number = {1},
  pages = {41--51},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2007.03.016},
  abstract = {OBJECTIVE: When studies report proportions such as sensitivity or specificity, it is customary to meta-analyze them using the DerSimonian and Laird random effects model. This method approximates the within-study variability of the proportion by a normal distribution, which may lead to bias for several reasons. Alternatively an exact likelihood approach based on the binomial within-study distribution can be used. This method can easily be performed in standard statistical packages. We investigate the performance of the standard method and the alternative approach. STUDY DESIGN AND SETTING: We compare the two approaches through a simulation study, in terms of bias, mean-squared error, and coverage probabilities. We varied the size of the overall sensitivity or specificity, the between-studies variance, the within-study sample sizes, and the number of studies. The methods are illustrated using a published meta-analysis data set. RESULTS: The exact likelihood approach performs always better than the approximate approach and gives unbiased estimates. The coverage probability, in particular for the profile likelihood, is also reasonably acceptable. In contrast, the approximate approach gives huge bias with very poor coverage probability in many cases. CONCLUSION: The exact likelihood approach is the method of preference and should be used whenever feasible.},
  langid = {english},
  pmid = {18083461},
  keywords = {Alzheimer Disease,Binomial Distribution,Data Interpretation Statistical,Diagnostic Techniques and Procedures,Fluorodeoxyglucose F18,Humans,Meta-Analysis as Topic,Models Statistical,Positron-Emission Tomography,Radiopharmaceuticals}
}

@article{nyagaMetapropStataCommand2014,
  title = {Metaprop: A {{Stata}} Command to Perform Meta-Analysis of Binomial Data},
  shorttitle = {Metaprop},
  author = {Nyaga, Victoria N. and Arbyn, Marc and Aerts, Marc},
  year = {2014},
  month = nov,
  journal = {Archives of Public Health},
  volume = {72},
  number = {1},
  pages = {39},
  issn = {2049-3258},
  doi = {10.1186/2049-3258-72-39},
  urldate = {2025-09-20},
  abstract = {Meta-analyses have become an essential tool in synthesizing evidence on clinical and epidemiological questions derived from a multitude of similar studies assessing the particular issue. Appropriate and accessible statistical software is needed to produce the summary statistic of interest.},
  keywords = {Binomial,Confidence intervals,Freeman-Tukey double arcsine transformation,Logistic-normal,Meta-analysis,Stata}
}

@article{snipenMicrobialComparativePangenomics2009,
  title = {Microbial Comparative Pan-Genomics Using Binomial Mixture Models},
  author = {Snipen, Lars and Alm{\o}y, Trygve and Ussery, David W.},
  year = {2009},
  month = aug,
  journal = {BMC Genomics},
  volume = {10},
  number = {1},
  pages = {385},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-10-385},
  urldate = {2025-09-20},
  abstract = {The size of the core- and pan-genome of bacterial species is a topic of increasing interest due to the growing number of sequenced prokaryote genomes, many from the same species. Attempts to estimate these quantities have been made, using regression methods or mixture models. We extend the latter approach by using statistical ideas developed for capture-recapture problems in ecology and epidemiology.},
  keywords = {Coxiella Burnetii,Detection Probability,Francisella Tularensis,Gene Family,Mixture Model}
}

@article{spartaBinomialModelsUncover2024,
  title = {Binomial Models Uncover Biological Variation during Feature Selection of Droplet-Based Single-Cell {{RNA}} Sequencing},
  author = {Sparta, Breanne and Hamilton, Timothy and Natesan, Gunalan and Aragones, Samuel D. and Deeds, Eric J.},
  year = {2024},
  month = sep,
  journal = {PLoS computational biology},
  volume = {20},
  number = {9},
  pages = {e1012386},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012386},
  abstract = {Effective analysis of single-cell RNA sequencing (scRNA-seq) data requires a rigorous distinction between technical noise and biological variation. In this work, we propose a simple feature selection model, termed "Differentially Distributed Genes" or DDGs, where a binomial sampling process for each mRNA species produces a null model of technical variation. Using scRNA-seq data where cell identities have been established a priori, we find that the DDG model of biological variation outperforms existing methods. We demonstrate that DDGs distinguish a validated set of real biologically varying genes, minimize neighborhood distortion, and enable accurate partitioning of cells into their established cell-type groups.},
  langid = {english},
  pmcid = {PMC11410258},
  pmid = {39241106},
  keywords = {Algorithms,Animals,Computational Biology,Gene Expression Profiling,Humans,Models Statistical,RNA Messenger,Sequence Analysis RNA,Single-Cell Analysis}
}

@article{young-xuPoolingOverdispersedBinomial2008,
  title = {Pooling Overdispersed Binomial Data to Estimate Event Rate},
  author = {{Young-Xu}, Yinong and Chan, K. Arnold},
  year = {2008},
  month = aug,
  journal = {BMC Medical Research Methodology},
  volume = {8},
  number = {1},
  pages = {58},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-8-58},
  urldate = {2025-09-20},
  abstract = {The beta-binomial model is one of the methods that can be used to validly combine event rates from overdispersed binomial data. Our objective is to provide a full description of this method and to update and broaden its applications in clinical and public health research.},
  langid = {english},
  keywords = {Dermatophytosis,Griseofulvin,Itraconazole,Terbinafine,Tinea Pedis}
}


@article{xue_regression_1997,
	title = {Regression analysis of discrete time survival data under heterogeneity},
	volume = {16},
	copyright = {Copyright © 1997 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819970915%2916%3A17%3C1983%3A%3AAID-SIM628%3E3.0.CO%3B2-3},
	doi = {10.1002/(SICI)1097-0258(19970915)16:17<1983::AID-SIM628>3.0.CO;2-3},
	abstract = {This paper concerns the regression analysis of discrete time survival data for heterogeneous populations by means of frailty models. We express the survival time for each individual as a sequence of binary variables that indicate if the individual survived at each time point. The main result is that the likelihood for these indicators can be factored into contributions that involve the conditional survival probabilities integrated over the frailty distribution of the risk set (population-averaged). We then model these population-averaged conditional probabilities as a function of covariates. The result justifies the practice of treating the failure indicators as independent Bernoulli trials and fitting binary regression models for the conditional failure probabilities at each time point. However, we must interpret the regression coefficients as population-averaged rather than subject-specific parameters. We apply the method to the Framingham Heart Study on risk factors for cardiovascular disease. © 1997 by John Wiley \& Sons, Ltd.},
	language = {en},
	number = {17},
	urldate = {2025-09-11},
	journal = {Statistics in Medicine},
	author = {Xue, Xiaonan and Brookmeyer, Ron},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0258\%2819970915\%2916\%3A17\%3C1983\%3A\%3AAID-SIM628\%3E3.0.CO\%3B2-3},
	pages = {1983--1993},
}

@inproceedings{bemando_machine-learning-based_2021,
	title = {Machine-{Learning}-{Based} {Prediction} {Models} of {Coronary} {Heart} {Disease} {Using} {Naïve} {Bayes} and {Random} {Forest} {Algorithms}},
	url = {https://ieeexplore.ieee.org/abstract/document/9537060},
	doi = {10.1109/ICSECS52883.2021.00049},
	abstract = {Coronary heart disease (CHD), alternatively known as cardiovascular disease (CVD) is the number one cause of death in the world. Accordingly, a plethora of research have been conducted to predict the early diagnosis of the heart disease and determine the most important risk factors associated with the disease. Despite these considerable efforts, the accuracy of the prediction has remained inadequate and the most important risk factors have remained elusive. This research paper discusses many risk factors associated with the disease and presents the prediction models of coronary heart disease using supervised machine learning algorithms, namely Gaussian Naïve Bayes, Bernoulli Naïve Bayes and Random Forest algorithms. It uses the public dataset from the Cleveland database of UCI repository of coronary heart disease patients. The results show that the Gaussian Naïve Bayes, Bernoulli Naïve Bayes and Random Forest algorithms have accuracies of 85.00\%, 85.00\% and 75.00\%, respectively. Moreover, the precision, F-measure and recall of the Gaussian and Bernoulli Naïve Bayes are higher than those of Random Forest algorithm, signifying its importance in predicting the early diagnosis of the disease.},
	urldate = {2025-09-11},
	booktitle = {2021 {International} {Conference} on {Software} {Engineering} \& {Computer} {Systems} and 4th {International} {Conference} on {Computational} {Science} and {Information} {Management} ({ICSECS}-{ICOCSIM})},
	author = {Bemando, Charles and Miranda, Eka and Aryuni, Mediana},
	month = aug,
	year = {2021},
	keywords = {Bernoulli Naïve Bayes, Computational modeling, Databases, factors, Gaussian Naïve Bayes, Heart, heart disease, machine learning, Machine learning algorithms, Prediction algorithms, Predictive models, Random Forest, risk, Scientific computing},
	pages = {232--237},
}

@misc{thompson_minimum_2010,
	title = {Minimum {Variance} {Estimators}},
	url = {https://faculty.washington.edu/eathomp/S341_10/Hwks/Cramer_Rao_soln.pdf},
	urldate = {2025-09-14},
	author = {Thompson, E.A.},
	month = feb,
	year = {2010},
}

@book{mccullagh_generalized_2018,
	address = {Boca Raton},
	title = {Generalized {Linear} {Models}},
	isbn = {978-0-412-31760-6},
	abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and other applications.The authors focus on examining the way a response variable depends on a combination of explanatory variables, treatment, and classification variables. They give particular emphasis to the important case where the dependence occurs through some unknown, linear combination of the explanatory variables.The Second Edition includes topics added to the core of the first edition, including conditional and marginal likelihood methods, estimating equations, and models for dispersion effects and components of dispersion. The discussion of other topics-log-linear and related models, log odds-ratio regression models, multinomial response models, inverse linear and related models, quasi-likelihood functions, and model checking-was expanded and incorporates significant revisions.Comprehension of the material requires simply a knowledge of matrix theory and the basic ideas of probability theory, but for the most part, the book is self-contained. Therefore, with its worked examples, plentiful exercises, and topics of direct use to researchers in many disciplines, Generalized Linear Models serves as ideal text, self-study guide, and reference.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {McCullagh, P. and Nelder, John A.},
	year = {2018},
}

@book{gelman_bayesian_2013,
	edition = {3},
	title = {Bayesian {Data} {Analysis}},
	publisher = {Chapman \& Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	year = {2013},
}

@book{hosmer_applied_2013,
	edition = {3},
	title = {Applied {Logistic} {Regression}},
	publisher = {Wiley},
	author = {Hosmer, David W. and Lemeshow, Stanley and Sturdivant, Rodney X.},
	month = mar,
	year = {2013},
}

@book{johnson_univariate_2005,
	edition = {3},
	title = {Univariate {Discrete} {Distributions}},
	isbn = {978-0-471-27246-5},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/0471715816},
	publisher = {Wiley},
	author = {Johnson, Norman L. and Kemp, Adrienne W. and Kotz, Samuel},
	month = jan,
	year = {2005},
}

@book{casella_statistical_2002,
	edition = {2},
	title = {Statistical {Inference}},
	publisher = {Duxbury Advanced Series},
	author = {Casella, George and Berger, L., Roger},
	year = {2002},
}

@article{agresti_approximate_1998,
	title = {Approximate is {Better} than “{Exact}” for {Interval} {Estimation} of {Binomial} {Proportions}},
	volume = {52},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.1998.10480550},
	doi = {10.1080/00031305.1998.10480550},
	abstract = {For interval estimation of a proportion, coverage probabilities tend to be too large for “exact” confidence intervals based on inverting the binomial test and too small for the interval based on inverting the Wald large-sample normal test (i.e., sample proportion ± z-score × estimated standard error). Wilson's suggestion of inverting the related score test with null rather than estimated standard error yields coverage probabilities close to nominal confidence levels, even for very small sample sizes. The 95\% score interval has similar behavior as the adjusted Wald interval obtained after adding two “successes” and two “failures” to the sample. In elementary courses, with the score and adjusted Wald methods it is unnecessary to provide students with awkward sample size guidelines.},
	number = {2},
	urldate = {2025-09-14},
	journal = {The American Statistician},
	author = {Agresti, Alan and Coull, Brent A.},
	month = may,
	year = {1998},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/00031305.1998.10480550},
	keywords = {Score test, Confidence interval, Discrete distribution, Exact inference, Poisson distribution, Small sample},
	pages = {119--126},
}

@article{wu_using_2020,
	title = {Using three statistical methods to analyze the association between exposure to 9 compounds and obesity in children and adolescents: {NHANES} 2005-2010},
	volume = {19},
	issn = {1476-069X},
	shorttitle = {Using three statistical methods to analyze the association between exposure to 9 compounds and obesity in children and adolescents},
	url = {https://doi.org/10.1186/s12940-020-00642-6},
	doi = {10.1186/s12940-020-00642-6},
	abstract = {Various risk factors influence obesity differently, and environmental endocrine disruption may increase the occurrence of obesity. However, most of the previous studies have considered only a unitary exposure or a set of similar exposures instead of mixed exposures, which entail complicated interactions. We utilized three statistical models to evaluate the correlations between mixed chemicals to analyze the association between 9 different chemical exposures and obesity in children and adolescents.},
	number = {1},
	urldate = {2025-09-15},
	journal = {Environmental Health},
	author = {Wu, Bangsheng and Jiang, Yi and Jin, Xiaoqing and He, Li},
	month = aug,
	year = {2020},
	keywords = {Adolescent, Bayesian kernel machine regression (BKMR), Child, Obesity, Weighted quantile sum (WQS) regression},
	pages = {94},
	file = {Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\93JAKXPD\\wu2020_using_three_statistical_methods_to_analyze_the_association_between_exposure_to_9_compounds_and_obesi.pdf:application/pdf;Snapshot:C\:\\Users\\samagonz\\Zotero\\storage\\UCE36KX7\\s12940-020-00642-6.html:text/html},
}


@article{branson_randomization-based_2019,
	title = {Randomization-based inference for {Bernoulli} trial experiments and implications for observational studies},
	volume = {28},
	issn = {0962-2802},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6027661/},
	doi = {10.1177/0962280218756689},
	abstract = {We present a randomization-based inferential framework for experiments characterized by a strongly ignorable assignment mechanism where units have independent probabilities of receiving treatment. Previous works on randomization tests often assume these probabilities are equal within blocks of units. We consider the general case where they differ across units and show how to perform randomization tests and obtain point estimates and confidence intervals. Furthermore, we develop rejection-sampling and importance-sampling approaches for conducting randomization-based inference conditional on any statistic of interest, such as the number of treated units or forms of covariate balance. We establish that our randomization tests are valid tests, and through simulation we demonstrate how the rejection-sampling and importance-sampling approaches can yield powerful randomization tests and thus precise inference. Our work also has implications for observational studies, which commonly assume a strongly ignorable assignment mechanism. Most methodologies for observational studies make additional modeling or asymptotic assumptions, while our framework only assumes the strongly ignorable assignment mechanism, and thus can be considered a minimal-assumption approach.},
	number = {5},
	urldate = {2025-09-15},
	journal = {Statistical methods in medical research},
	author = {Branson, Zach and Bind, Marie-Abèle},
	month = may,
	year = {2019},
	pmid = {29451089},
	pmcid = {PMC6027661},
	pages = {1378--1398},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\I3ABLUJF\\branson and bind2019_randomization-based_inference_for_bernoulli_trial_experiments_and_implications_for_observational_stu.pdf:application/pdf},
}

@article{agegnehu_exploring_2021,
	title = {Exploring spatial variation in {BCG} vaccination among children 0–35 months in {Ethiopia}: spatial analysis of {Ethiopian} {Demographic} and {Health} {Survey} 2016},
	volume = {11},
	issn = {2044-6055},
	shorttitle = {Exploring spatial variation in {BCG} vaccination among children 0–35 months in {Ethiopia}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8094339/},
	doi = {10.1136/bmjopen-2020-043565},
	abstract = {Objective
Tuberculosis is a major public health problem and is the second leading cause of death worldwide. BCG vaccination is a life-saving and important part of standard tuberculosis control measures, particularly in Ethiopia where tuberculosis is endemic. The End Tuberculosis Strategy targets of 2020 have not been achieved. Exploring spatial variations in BCG vaccination among children is vital to designing and monitoring effective intervention programmes. Therefore, this study aimed to explore the spatial variation in BCG vaccination among children in Ethiopia.

Design
Cross-sectional study design.

Setting
Ethiopia.

Participants
Children aged 0–35 months.

Primary outcome
BCG vaccination coverage.

Methods
Data from the 2016 Ethiopian Demographic and Health Survey were used and a total of 4453 children aged 0–35 months were included. Spatial autocorrelation analysis, cluster and outlier analysis, hotspot analysis, spatial interpolation, and spatial scan statistics were carried out to identify geographical risk areas for BCG vaccine utilisation. ArcGIS V.10.6 and SaTScan V.9.6 statistical software were employed to explore spatial pattern and significant hotspot areas for BCG vaccination among children.

Results
BCG vaccination was spatially clustered in Ethiopia at the regional level (Global Moran’s I=0.516, p{\textless}0.001). A total of 51 most likely clusters of low BCG vaccination were identified in the Somali and Afar regions (log-likelihood ratio=136.58, p{\textless}0.001). Significant secondary clusters were also identified in North West Gambela, South Amhara, South West Addis Ababa, North East Southern Nations, Nationalities, and People’s Region, and South West Oromia.

Conclusion
A low probability of receiving BCG vaccination was found among children in the Somali and Afar regions. Therefore, these areas should be given attention when designing effective immunisation strategies to improve BCG vaccination among children in order to reduce the burden of tuberculosis in Ethiopia.},
	number = {4},
	urldate = {2025-09-15},
	journal = {BMJ Open},
	author = {Agegnehu, Chilot Desta and Alem, Adugnaw Zeleke},
	month = apr,
	year = {2021},
	pmid = {33910946},
	pmcid = {PMC8094339},
	pages = {e043565},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\N568DTZR\\agegnehu and alem2021_exploring_spatial_variation_in_bcg_vaccination_among_children_0–35_months_in_ethiopia_spatial_analy.pdf:application/pdf},
}

@article{abbasi_partial_2022,
	title = {On partial randomized response model using ranked set sampling},
	volume = {17},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9707803/},
	doi = {10.1371/journal.pone.0277497},
	abstract = {In this paper, we propose a partial randomized response technique to collect reliable sensitive data for estimation of population proportion in ranked set sampling (RSS) scheme using auxiliary information. The idea is to increase confidence and (or) co-operation of the respondents by providing them the option of both ‘direct’ and ‘randomized’ response for the inquired sensitive question. This option is quite logical because perception of sensitive (insensitive) inquiry can vary among respondents. The properties of the proposed method are discussed and compared with existing randomized response techniques. Cost analysis is also carried out to prove supremacy of the suggested method. Finally, an application to clinical trial on AIDS is included.},
	number = {11},
	urldate = {2025-09-15},
	journal = {PLOS ONE},
	author = {Abbasi, Azhar Mehmood and Shad, Muhammad Yousaf and Ahmed, Aneel},
	month = nov,
	year = {2022},
	pmid = {36445862},
	pmcid = {PMC9707803},
	pages = {e0277497},
	file = {PubMed Central Full Text PDF:C\:\\Users\\samagonz\\Zotero\\storage\\F3Z8WMDW\\abbasi2022_on_partial_randomized_response_model_using_ranked_set_sampling.pdf:application/pdf},
}

@article{liAgeStratifiedPoissonModel2008,
  title = {An {{Age-Stratified Poisson Model}} for {{Comparing Trends}} in {{Cancer Rates Across Overlapping Regions}}},
  author = {Li, Yi and Tiwari, Ram C. and Zou, Zhaohui},
  year = 2008,
  month = aug,
  journal = {Biometrical journal. Biometrische Zeitschrift},
  volume = {50},
  number = {4},
  pages = {608--619},
  issn = {0323-3847},
  doi = {10.1002/bimj.200710430},
  urldate = {2025-10-16},
  abstract = {The annual percent change (APC) has been used as a measure to describe the trend in the age-adjusted cancer incidence or mortality rate over relatively short time intervals. The yearly data on these age-adjusted rates are available from the Surveillance, Epidemiology, and End Results (SEER) Program of the National Cancer Institute. The traditional methods to estimate the APC is to fit a linear regression of logarithm of age-adjusted rates on time using the least squares method or the weighted least squares method, and use the estimate of the slope parameter to define the APC as the percent change in the rates between two consecutive years. For comparing the APC for two regions, one uses a t-test which assumes that the two datasets on the logarithm of the age-adjusted rates are independent and normally distributed with a common variance. Two modifications of this test, when there is an overlap between the two regions or between the time intervals for the two datasets have been recently developed. The first modification relaxes the assumption of the independence of the two datasets but still assumes the common variance. The second modification relaxes the assumption of the common variance also, but assumes that the variances of the age-adjusted rates are obtained using Poisson distributions for the mortality or incidence counts. In this paper, a unified approach to the problem of estimating the APC is undertaken by modeling the counts to follow an age-stratified Poisson regression model, and by deriving a corrected Z-test for testing the equality of two APCs. A simulation study is carried out to assess the performance of the test and an application of the test to compare the trends, for a selected number of cancer sites, for two overlapping regions and with varied degree of overlapping time intervals is presented.},
  pmcid = {PMC2536754},
  pmid = {18615411},
  file = {C:\Users\sbelg\Zotero\storage\3S96IKV8\li2008_an_age-stratified_poisson_model_for_comparing_trends_in_cancer_rates_across_overlapping_regions.pdf}
}

@article{sunStatisticalAnalysisSpatial2020a,
  title = {Statistical {{Analysis}} of {{Spatial Expression Pattern}} for {{Spatially Resolved Transcriptomic Studies}}},
  author = {Sun, Shiquan and Zhu, Jiaqiang and Zhou, Xiang},
  year = 2020,
  month = feb,
  journal = {Nature methods},
  volume = {17},
  number = {2},
  pages = {193--200},
  issn = {1548-7091},
  doi = {10.1038/s41592-019-0701-7},
  urldate = {2025-10-16},
  abstract = {Identifying genes that display spatial expression pattern in spatially resolved transcriptomic studies is an important first step towards characterizing the spatial transcriptomic landscape of complex tissues. Here, we developed a statistical method, SPARK, for identifying such spatially expressed genes in data generated from various spatially resolved transcriptomic techniques. SPARK directly models spatial count data through the generalized linear spatial models. It relies on newly developed statistical formulas for hypothesis testing, providing effective type I error control and yielding high statistical power. With a computationally efficient algorithm based on penalized quasi-likelihood, SPARK is also scalable to data sets with tens of thousands of genes measured on tens of thousands of samples. In four published spatially resolved transcriptomic data sets, we show that SPARK can be up to ten times more powerful than existing methods, revealing new biology in the data that otherwise cannot be revealed by existing approaches.},
  pmcid = {PMC7233129},
  pmid = {31988518},
  file = {C:\Users\sbelg\Zotero\storage\SUDNZ5KV\sun2020_statistical_analysis_of_spatial_expression_pattern_for_spatially_resolved_transcriptomic_studies.pdf}
}

@article{zhaoCOVID19ShortTerm2021,
  title = {{{COVID-19}}: {{Short}} Term Prediction Model Using Daily Incidence Data},
  shorttitle = {{{COVID-19}}},
  author = {Zhao, Hongwei and Merchant, Naveed N. and McNulty, Alyssa and Radcliff, Tiffany A. and Cote, Murray J. and Fischer, Rebecca S. B. and Sang, Huiyan and Ory, Marcia G.},
  year = 2021,
  month = apr,
  journal = {PLOS ONE},
  volume = {16},
  number = {4},
  pages = {e0250110},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0250110},
  urldate = {2025-10-16},
  abstract = {Background Prediction of the dynamics of new SARS-CoV-2 infections during the current COVID-19 pandemic is critical for public health planning of efficient health care allocation and monitoring the effects of policy interventions. We describe a new approach that forecasts the number of incident cases in the near future given past occurrences using only a small number of assumptions. Methods Our approach to forecasting future COVID-19 cases involves 1) modeling the observed incidence cases using a Poisson distribution for the daily incidence number, and a gamma distribution for the series interval; 2) estimating the effective reproduction number assuming its value stays constant during a short time interval; and 3) drawing future incidence cases from their posterior distributions, assuming that the current transmission rate will stay the same, or change by a certain degree. Results We apply our method to predicting the number of new COVID-19 cases in a single state in the U.S. and for a subset of counties within the state to demonstrate the utility of this method at varying scales of prediction. Our method produces reasonably accurate results when the effective reproduction number is distributed similarly in the future as in the past. Large deviations from the predicted results can imply that a change in policy or some other factors have occurred that have dramatically altered the disease transmission over time. Conclusion We presented a modelling approach that we believe can be easily adopted by others, and immediately useful for local or state planning.},
  langid = {english},
  keywords = {COVID 19,Epidemiology,Forecasting,Infectious diseases,Pandemics,Public and occupational health,Texas,Valleys},
  file = {C:\Users\sbelg\Zotero\storage\SENQRHXP\zhao2021_covid-19_short_term_prediction_model_using_daily_incidence_data.pdf}
}

@article{zhaoEpidemiologicalAnalysisSecond2022,
  title = {Epidemiological Analysis of Second Primary Malignant Neoplasms in Cancer Survivors Aged 85 Years and Older: A {{SEER}} Data Analysis (1975--2016)},
  shorttitle = {Epidemiological Analysis of Second Primary Malignant Neoplasms in Cancer Survivors Aged 85 Years and Older},
  author = {Zhao, Xianlan and Zhang, Li and Bai, Lanjun and Zhao, Yangyang and Yang, Qiao},
  year = 2022,
  month = jul,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {11688},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-15746-x},
  urldate = {2025-10-16},
  abstract = {Cancer burden in patients aged 85~years and older has rapidly increased accompanying the decrease in mortality, which is raising the concern of developing second primary malignant neoplasms (SPM). This study aimed to investigate the epidemiology of the SPM in this population in the US by using the surveillance, epidemiology, and end results database (1975--2016). The cumulative incidence of developing a SPM was calculated by the Fine and Gray model. Standardized incidence ratios (SIR) were calculated via Poisson regression. The relative post-SPM survival rate was calculated by the Kaplan--Meier method. Male patients with skin melanoma, kidney and renal pelvis and urinary bladder cancers had high cumulative incidences (15.32\%, 13.55\%, and 12.26\%, respectively) and increased SIRs (1.47, 1.44, and 1.16, respectively) for developing SPMs. Female patients with skin melanoma and urinary bladder cancers had high cumulative incidences (10.18\% and 7.87\%, respectively) and increased SIRs (1.34 and 1.18, respectively). In general, the incidence of SPM cases increased over time. The median latency ranged from 17 to 37~months. A less than 50\% of patients had 1-year post-SPM survival. In conclusion, some of these patients had an increased risk of the SPM, with poor survival.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cancer,Cancer epidemiology},
  file = {C:\Users\sbelg\Zotero\storage\J7RQVHDH\zhao2022_epidemiological_analysis_of_second_primary_malignant_neoplasms_in_cancer_survivors_aged_85_years_and.pdf}
}

@book{bortkiewicz1898, 
  author = {Ladislaus von Bortkiewicz}, 
  title = {Das Gesetz der kleinen Zahlen}, 
  year = {1898}, publisher = {B. G. Teubner}, 
  address = {Leipzig}, 
  note = {Seminal work applying the Poisson distribution to Prussian cavalry horse-kick deaths.} 
}

@book{stigler1986, 
  author = {Stephen M. Stigler}, 
  title = {The History of Statistics: The Measurement of Uncertainty before 1900}, 
  year = {1986}, publisher = {Harvard University Press}, 
  address = {Cambridge, MA}, 
  note = {Includes context for Poisson’s and Bortkiewicz’s contributions.} 
}

@article{cowan_note_nodate,
	title = {Note on the {Poisson} {Distribution}},
	language = {en},
	author = {Cowan, Glen}
}

@book{gelman2013bayesian,
  title     = {Bayesian Data Analysis},
  author    = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. 
               and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  year      = {2013},
  edition   = {3rd},
  publisher = {CRC Press},
  address   = {Boca Raton, FL},
  note      = {Foundational reference for Beta-Binomial conjugacy.}
}

@book{johnson1995continuous,
  title     = {Continuous Univariate Distributions, Volume 2},
  author    = {Johnson, Norman L. and Kotz, Samuel and Balakrishnan, N.},
  year      = {1995},
  publisher = {Wiley},
  address   = {New York},
  note      = {Classic reference detailing properties of the Beta distribution.}
}

@article{minka2002estimating,
  title   = {Estimating a Dirichlet Distribution},
  author  = {Minka, Thomas P.},
  journal = {Technical Report, MIT},
  year    = {2002},
  url     = {https://tminka.github.io/papers/dirichlet/minka-dirichlet.pdf},
  note    = {Practical algorithms for estimating Beta/Dirichlet parameters.}
}
